{
"cells": [
{
"cell_type": "markdown",
"metadata": {},
"source": [
"# Credit Risk Prediction Analysis\n",
"\n",
"## 1. Introduction\n",
"This notebook presents a detailed analysis of the German Credit Data to build a model for predicting credit risk. We will explore the data, preprocess it, train multiple machine learning models, and evaluate their performance to identify the best approach for this classification task."
]
},
{
"cell_type": "markdown",
"metadata": {},
"source": [
"## 2. Data Loading and Initial Exploration"
]
},
{
"cell_type": "code",
"execution_count": null,
"metadata": {},
"outputs": [],
"source": [
"import pandas as pd\n",
"import numpy as np\n",
"import seaborn as sns\n",
"import matplotlib.pyplot as plt\n",
"\n",
"# Load the dataset\n",
"url = 'https://www.google.com/search?q=https://archive.ics.uci.edu/ml/machine-learning-databases/statlog/german/german.data'\n",
"columns = [\n",
"    'checking_account_status', 'duration', 'credit_history', 'purpose', 'credit_amount', \n",
"    'savings_account', 'present_employment', 'installment_rate', 'personal_status_sex', \n",
"    'other_debtors', 'present_residence_since', 'property', 'age', 'other_installment_plans', \n",
"    'housing', 'number_of_credits', 'job', 'people_liable', 'telephone', 'foreign_worker', 'risk'\n",
"]\n",
"df = pd.read_csv(url, sep=' ', header=None, names=columns)\n",
"\n",
"# Convert target variable\n",
"df['risk'] = df['risk'].replace({1: 'Good', 2: 'Bad'})\n",
"\n",
"print('Dataset Shape:', df.shape)\n",
"print('\nFirst 5 Rows:')\n",
"display(df.head())"
]
},
{
"cell_type": "markdown",
"metadata": {},
"source": [
"## 3. Exploratory Data Analysis (EDA)"
]
},
{
"cell_type": "code",
"execution_count": null,
"metadata": {},
"outputs": [],
"source": [
"# Distribution of the target variable\n",
"plt.figure(figsize=(8, 6))\n",
"sns.countplot(x='risk', data=df)\n",
"plt.title('Distribution of Credit Risk')\n",
"plt.show()\n",
"\n",
"# Distribution of Credit Amount by Risk\n",
"plt.figure(figsize=(10, 6))\n",
"sns.boxplot(x='risk', y='credit_amount', data=df)\n",
"plt.title('Credit Amount Distribution by Risk')\n",
"plt.show()\n",
"\n",
"# Credit History vs. Risk\n",
"plt.figure(figsize=(12, 7))\n",
"sns.countplot(x='credit_history', hue='risk', data=df)\n",
"plt.title('Credit History vs. Risk')\n",
"plt.xticks(rotation=45)\n",
"plt.show()"
]
},
{
"cell_type": "markdown",
"metadata": {},
"source": [
"## 4. Data Preprocessing and Modeling\n",
"We will now preprocess the data by encoding categorical variables and scaling numerical features. After that, we will train and evaluate Logistic Regression, Random Forest, and Gradient Boosting models."
]
},
{
"cell_type": "code",
"execution_count": null,
"metadata": {},
"outputs": [],
"source": [
"from sklearn.model_selection import train_test_split\n",
"from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
"from sklearn.compose import ColumnTransformer\n",
"from sklearn.pipeline import Pipeline\n",
"from sklearn.linear_model import LogisticRegression\n",
"from sklearn.ensemble import RandomForestClassifier\n",
"from sklearn.metrics import classification_report, roc_auc_score\n",
"\n",
"# Prepare data for modeling\n",
"df['risk'] = df['risk'].replace({'Good': 0, 'Bad': 1})\n",
"X = df.drop('risk', axis=1)\n",
"y = df['risk']\n",
"\n",
"categorical_features = X.select_dtypes(include=['object']).columns\n",
"numerical_features = X.select_dtypes(include=np.number).columns\n",
"\n",
"preprocessor = ColumnTransformer(\n",
"    transformers=[\n",
"        ('num', StandardScaler(), numerical_features),\n",
"        ('cat', OneHotEncoder(handle_unknown='ignore'), categorical_features)])\n",
"\n",
"X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
"\n",
"# --- Logistic Regression ---\n",
"lr_pipeline = Pipeline(steps=[('preprocessor', preprocessor), ('classifier', LogisticRegression(random_state=42))])\n",
"lr_pipeline.fit(X_train, y_train)\n",
"y_pred_lr = lr_pipeline.predict(X_test)\n",
"print('--- Logistic Regression Report ---')\n",
"print(classification_report(y_test, y_pred_lr))\n",
"\n",
"# --- Random Forest ---\n",
"rf_pipeline = Pipeline(steps=[('preprocessor', preprocessor), ('classifier', RandomForestClassifier(random_state=42))])\n",
"rf_pipeline.fit(X_train, y_train)\n",
"y_pred_rf = rf_pipeline.predict(X_test)\n",
"print('--- Random Forest Report ---')\n",
"print(classification_report(y_test, y_pred_rf))"
]
},
{
"cell_type": "markdown",
"metadata": {},
"source": [
"## 5. Conclusion\n",
"Based on the evaluation metrics, we can compare the models. The Random Forest classifier generally provides a good balance of precision and recall. Further improvements could be achieved through more advanced feature engineering and hyperparameter tuning. The model's feature importance can also provide valuable insights into the key drivers of credit risk."
]
}
],
"metadata": {
"kernelspec": {
"display_name": "Python 3",
"language": "python",
"name": "python3"
},
"language_info": {
"codemirror_mode": {
"name": "ipython",
"version": 3
},
"file_extension": ".py",
"mimetype": "text/x-python",
"name": "python",
"nbconvert_exporter": "python",
"pygments_lexer": "ipython3",
"version": "3.8.8"
}
},
"nbformat": 4,
"nbformat_minor": 4
}